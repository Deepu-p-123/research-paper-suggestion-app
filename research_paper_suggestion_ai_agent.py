# -*- coding: utf-8 -*-
"""Research Paper Suggestion AI Agent

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WJGb1vlGQTDsBK4BXuymiOT-2A7Y_QrL
"""

import pandas as pd
import requests
import numpy as np
from transformers import pipeline

try:
    summarizer = pipeline("summarization", model="facebook/bart-large-cnn")
except Exception as e:
    summarizer = None
    print("Summarizer pipeline unavailable. Showing plain abstracts.")

import requests
import xml.etree.ElementTree as ET

def arxiv_search(query, max_results=5):
    search_url = f'http://export.arxiv.org/api/query?search_query=all:{query}&start=0&max_results={max_results}'
    resp = requests.get(search_url)
    papers = []
    if resp.status_code == 200:
        root = ET.fromstring(resp.content)
        namespace = {'arxiv': 'http://arxiv.org/schemas/atom'}
        for entry in root.findall('{http://www.w3.org/2005/Atom}entry'):
            title = entry.find('{http://www.w3.org/2005/Atom}title').text.strip()
            summary = entry.find('{http://www.w3.org/2005/Atom}summary').text.strip()
            authors = [author.find('{http://www.w3.org/2005/Atom}name').text for author in entry.findall('{http://www.w3.org/2005/Atom}author')]
            published = entry.find('{http://www.w3.org/2005/Atom}published').text
            link = entry.find('{http://www.w3.org/2005/Atom}id').text
            papers.append({'title': title,'authors': authors,'published': published,'summary': summary,'link': link})
    return papers

user_topic = input("Enter your research topic or question: ")
arxiv_results = arxiv_search(user_topic)
for i, p in enumerate(arxiv_results, 1):
    print(f"{i}. {p['title']} ({p['published'][:10]})")
    print(f"   Authors: {', '.join(p['authors'])}")
    print(f"   Link: {p['link']}")
    print(f"   Summary: {p['summary'][:300]}...\n")